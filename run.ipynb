{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast as autocast\n",
    "from torch.cuda.amp import GradScaler\n",
    "\n",
    "# from model.unet import Model      # UNet\n",
    "# from model.efficientnet_unet import Model  # EfficientNet (Encoder) + UNet (Decoder)\n",
    "# from model.efficientnet_cbam_unet import Model  # EfficientNet (Encoder) + CBAM + UNet (Decoder)\n",
    "from model.fine_tune import Model  # EfficientNet (Encoder) + CBAM + UNet (Decoder) + Fine-tune\n",
    "\n",
    "from dataset.dataset import Dataset\n",
    "from dataset.align import inverseTensor\n",
    "from utils.visualize import visualize_predictions, visualize_predictions_jupyter\n",
    "from utils.mask import combine_masks, predict_masks, create_masks_dict, save_images_if_required, reorder_dict_data\n",
    "from utils.metrics import SegMetric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Global Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze seed\n",
    "torch.manual_seed(0)\n",
    "\n",
    "# Define paths\n",
    "CHECKPOINT_PATH = ''\n",
    "TRAIN_INDEX_PATH = 'data/train_toy_idx.txt'\n",
    "TEST_INDEX_PATH = 'data/test_toy_idx.txt'\n",
    "UNSEEN_INDEX_PATH = 'data/test_lapa_idx.txt'\n",
    "\n",
    "# Define modes\n",
    "MODE ='train'                               # train / test / csv\n",
    "RECORD = False                              # Record predictions in wandb\n",
    "SAVE_MODEL_NAME = 'Unseen'  # Name of model to save\n",
    "SAVE_IMAGES = False                         # Save images \n",
    "EXPORT_TO_CSV_AFTER_TRAIN = True            # Export predictions to csv after training\n",
    "JUPYTER_NOTEBOOK = True                     # Run in Jupyter Notebook\n",
    "UNSEEN = True                              # Test on unseen data\n",
    "SAVE_CSV = True                            # Save csv file\n",
    "\n",
    "# Define hyperparameters\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE = 1\n",
    "LEARNING_RATE = 1e-4\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup WanDB for tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "def get_current_timestamp():\n",
    "    now = datetime.now()\n",
    "    timestamp = now.strftime(\"%Y_%m_%d_%H%M%S\")\n",
    "    return timestamp\n",
    "\n",
    "timestamp = get_current_timestamp()\n",
    "log_dir = f'checkpoint/{timestamp}_{SAVE_MODEL_NAME}'\n",
    "\n",
    "if RECORD and MODE == 'train':\n",
    "    wandb.init(\n",
    "        # set the wandb project where this run will be logged\n",
    "        project=\"Face_Segmentation\",\n",
    "        name=f'{timestamp}_{SAVE_MODEL_NAME}',\n",
    "        \n",
    "        # track hyperparameters and run metadata\n",
    "        config={\n",
    "        \"learning_rate\": 1e-4,\n",
    "        \"architecture\": \"CNN\",\n",
    "        \"dataset\": \"CelebAMaskHQ\",\n",
    "        \"epochs\": 20,\n",
    "        \"Dropout\": 0,\n",
    "        \"CBAM\": \"reduction_ratio=16, kernel_size=5\",\n",
    "        \"batch_size\": 6,\n",
    "        \"EfficientNet\": \"b7\",\n",
    "        }\n",
    "    )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Current Working Directory to current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change current working directory to file location\n",
    "if JUPYTER_NOTEBOOK:\n",
    "    current_folder = globals()['_dh'][0]\n",
    "    os.chdir(current_folder)\n",
    "else:\n",
    "    os.chdir(os.path.dirname(__file__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class loss(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(loss, self).__init__()\n",
    "        self.loss = nn.CrossEntropyLoss()\n",
    "        self.weights = torch.tensor([\n",
    "            0.0, 0.0, 0.4, \n",
    "            0.4, 1.0, 1.0, 0.3, \n",
    "            0.0, 0.0, 0.0, 0.0,\n",
    "            0.0, 0.0, 0.0, 0.0,\n",
    "            0.0, 0.0, 0.0, 0.0], dtype=torch.float).to(device)\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        cross_entropy = F.cross_entropy(output, target, weight=self.weights)\n",
    "        regularization_loss = torch.sum(self.weights ** 2)\n",
    "        return cross_entropy + regularization_loss * 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b7\n",
      "Total number of parameters: 163028819\n"
     ]
    }
   ],
   "source": [
    "# Create U-Net model\n",
    "model = Model(3, 19)\n",
    "model = nn.DataParallel(model)\n",
    "model = model.to(device)\n",
    "\n",
    "# Print total number of parameters\n",
    "print(f'Total number of parameters: {sum(p.numel() for p in model.parameters())}')\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = loss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Load dataset\n",
    "train_dataset = Dataset(id_file=TRAIN_INDEX_PATH, transform=ToTensor())\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "if UNSEEN:\n",
    "    test_dataset = Dataset(id_file=UNSEEN_INDEX_PATH, transform=ToTensor(), unseen=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "else:\n",
    "    test_dataset = Dataset(id_file=TEST_INDEX_PATH, transform=ToTensor())\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup TA Prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_celeb = ['background', 'skin', 'l_brow', \n",
    "                'r_brow', 'l_eye', 'r_eye', 'eye_g', \n",
    "                'l_ear', 'r_ear', 'ear_r', 'nose', \n",
    "                'mouth', 'u_lip', 'l_lip', 'neck', \n",
    "                'neck_l', 'cloth', 'hair', 'hat']\n",
    "# [0.0, 0.0, 0.4, \n",
    "# 0.4, 1.0, 1.0, 0.3, \n",
    "# 0.0, 0.0, 0.0, 0.0,\n",
    "# 0.0, 0.0, 0.0, 0.0,\n",
    "# 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "labels_celeb_origin = ['background', 'skin', 'nose',\n",
    "                       'eye_g', 'l_eye', 'r_eye', 'l_brow',\n",
    "                       'r_brow', 'l_ear', 'r_ear', 'mouth',\n",
    "                       'u_lip', 'l_lip', 'hair', 'hat',\n",
    "                       'ear_r', 'neck_l', 'neck', 'cloth']\n",
    "\n",
    "\n",
    "def read_mask(path):\n",
    "    img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
    "    if type(img) is type(None):\n",
    "        return np.zeros((256, 256, 1), dtype=np.uint8)\n",
    "    return img\n",
    "\n",
    "\n",
    "def mask2binary(path):\n",
    "    mask = read_mask(path)\n",
    "    mask = cv2.resize(mask, (256, 256), interpolation=cv2.INTER_NEAREST)\n",
    "    mask = np.where(mask > 0, 1, 0)\n",
    "    return mask\n",
    "\n",
    "\n",
    "def rle_encode(img):\n",
    "    pixels = img.flatten()\n",
    "    if np.sum(pixels) == 0:\n",
    "        return '0'\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    # to string sep='_'\n",
    "    runs = '_'.join(str(x) for x in runs)\n",
    "    return runs\n",
    "\n",
    "\n",
    "def rle_decode(mask_rle, shape):\n",
    "    s = mask_rle.split('_')\n",
    "    s = [0 if x == '' else int(x) for x in s]\n",
    "    if np.sum(s) == 0:\n",
    "        return np.zeros(shape, dtype=np.uint8)\n",
    "    starts, lengths = [np.asarray(x, dtype=int)\n",
    "                       for x in (s[0:][::2], s[1:][::2])]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n",
    "    for lo, hi in zip(starts, ends):\n",
    "        img[lo:hi] = 255\n",
    "    return img.reshape(shape)\n",
    "\n",
    "\n",
    "def mask2csv(mask_paths, csv_path='mask.csv', image_id=1):\n",
    "    results = []\n",
    "    for label in labels_celeb_origin:\n",
    "        try:\n",
    "            mask = mask2binary(mask_paths[label])\n",
    "        except:\n",
    "            mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "        mask = rle_encode(mask)\n",
    "        results.append(mask)\n",
    "\n",
    "    df = pd.DataFrame(results)\n",
    "    df.insert(0, 'label', labels_celeb_origin)\n",
    "    df.insert(0, 'Usage', [\"Public\" for _ in range(len(results))])\n",
    "    df.insert(0, 'ID', [image_id * 19 + i for i in range(19)])\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        df.columns = ['ID', 'Usage', 'label', 'segmentation']\n",
    "        df.to_csv(csv_path, mode='w', header=True, index=False)\n",
    "    else:\n",
    "        df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "def mask2csv2(masks, csv_path='mask.csv', image_id=0):\n",
    "    \"\"\"\n",
    "        mask_paths: dict of label:mask\n",
    "        ['label1':mask1,'label2':mask2,...]\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for i, label in enumerate(labels_celeb_origin):\n",
    "        try:\n",
    "            mask = masks[label]\n",
    "        except:\n",
    "            mask = np.zeros((256, 256), dtype=np.uint8)\n",
    "        mask = rle_encode(mask)\n",
    "        results.append(mask)\n",
    "    df = pd.DataFrame(results)\n",
    "    df.insert(0, 'label', labels_celeb_origin)\n",
    "    df.insert(0, 'Usage', [\"Public\" for i in range(len(results))])\n",
    "    df.insert(0, 'ID', [image_id*19+i for i in range(19)])\n",
    "\n",
    "    if not os.path.exists(csv_path):\n",
    "        df.columns = ['ID', 'Usage', 'label', 'segmentation']\n",
    "        df.to_csv(csv_path, mode='w', header=True, index=False)\n",
    "    else:\n",
    "        df.to_csv(csv_path, mode='a', header=False, index=False)\n",
    "\n",
    "\n",
    "def export_model_to_csv(model, test_loader, save_images=False):\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "    model.eval()\n",
    "\n",
    "    if not os.path.exists(log_dir) and SAVE_CSV:\n",
    "        os.makedirs(log_dir)\n",
    "    if os.path.exists(f'{log_dir}/mask.csv') and SAVE_CSV:\n",
    "        os.rename(f'{log_dir}/mask.csv', f'{log_dir}/mask_{get_current_timestamp()}.csv')\n",
    "    with torch.no_grad():\n",
    "        for images, masks, idx, aligned_size, original_img_shape, r_mat  in tqdm(test_loader):\n",
    "            images, masks = images.to(device), masks.to(device).squeeze(1)\n",
    "            predicted = predict_masks(model, images, aligned_size, original_img_shape, r_mat)\n",
    "            if idx[0].item() % 100 == 0:\n",
    "                fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "                axes[0].imshow(images[0].cpu().numpy().transpose(1, 2, 0))\n",
    "                axes[1].imshow(predicted[0].squeeze(0).cpu().numpy())\n",
    "                plt.show()\n",
    "\n",
    "            dict_data_batch = create_masks_dict(predicted, labels_celeb)\n",
    "            save_images_if_required(dict_data_batch, idx, labels_celeb, save_images)\n",
    "\n",
    "            for i, dict_data in enumerate(dict_data_batch):\n",
    "                reordered_dict_data = reorder_dict_data(dict_data, labels_celeb_origin)\n",
    "                if SAVE_CSV:\n",
    "                    mask2csv2(reordered_dict_data, csv_path=f'{log_dir}/mask.csv', image_id=idx[i].item())\n",
    "                \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, test_loader, criterion, optimizer):\n",
    "    global CHECKPOINT_PATH\n",
    "    lowest_test_loss = 1e10\n",
    "    if CHECKPOINT_PATH != '':\n",
    "        model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "        print('Loaded model from checkpoint.')\n",
    "    model.train()\n",
    "    all_train_loss = []\n",
    "    all_test_loss = []\n",
    "    scaler = GradScaler()\n",
    "    for epoch in tqdm(range(EPOCHS), leave=True):\n",
    "        for images, masks, _, aligned_size, original_img_shape, r_mat in tqdm(train_loader, leave=False):\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device).squeeze(1)\n",
    "\n",
    "            # Forward pass\n",
    "            with autocast():\n",
    "                outputs = model(images)\n",
    "                train_loss = criterion(outputs, masks)\n",
    "                \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            scaler.scale(train_loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            # train_loss.backward()\n",
    "            # optimizer.step()\n",
    "            \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            metrics = SegMetric(n_classes = 19)\n",
    "            metrics.reset()\n",
    "            for images, masks, _, aligned_size, original_img_shape, r_mat in tqdm(test_loader, leave=False):\n",
    "                images = images.to(device)\n",
    "                masks = masks.to(device).squeeze(1)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(images)\n",
    "                test_loss = criterion(outputs, masks)\n",
    "                \n",
    "                # Update F1 score\n",
    "                pred = outputs.data.max(1)[1].cpu().numpy()  # Matrix index\n",
    "                gt = combine_masks(masks).cpu().numpy()\n",
    "                metrics.update(gt, pred)\n",
    "                \n",
    "            # Save model with lowest test loss\n",
    "            if test_loss.item() < lowest_test_loss:\n",
    "                lowest_test_loss = test_loss.item()\n",
    "                if not os.path.exists(log_dir) and MODE == 'train':\n",
    "                    os.makedirs(log_dir)\n",
    "                if os.path.exists(f'{log_dir}/{SAVE_MODEL_NAME}.pth'):\n",
    "                    os.rename(f'{log_dir}/{SAVE_MODEL_NAME}.pth', f'{log_dir}/{SAVE_MODEL_NAME}_{get_current_timestamp()}.pth')\n",
    "                torch.save(model.state_dict(), f'{log_dir}/{SAVE_MODEL_NAME}.pth')\n",
    "\n",
    "            F1_score = metrics.get_f1_score()\n",
    "            \n",
    "            tqdm.write(f'Epoch [{epoch+1}/{EPOCHS}], Train Loss: {train_loss.item():.4f}, Test Loss: {test_loss.item():.4f}, F1 Score: {F1_score:.4f}')\n",
    "            all_train_loss.append(train_loss.item())\n",
    "            all_test_loss.append(test_loss.item())\n",
    "\n",
    "        if RECORD:\n",
    "            wandb.log({\"train_loss\": train_loss.item(), \"test_loss\": test_loss.item(), \"F1_score\": F1_score})\n",
    "\n",
    "    # Plot loss\n",
    "    plt.plot(all_train_loss, label='Training loss')\n",
    "    plt.plot(all_test_loss, label='Testing loss')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{log_dir}/loss.png')\n",
    "\n",
    "    # Export predictions to csv\n",
    "    if EXPORT_TO_CSV_AFTER_TRAIN:\n",
    "        CHECKPOINT_PATH = f'{log_dir}/{SAVE_MODEL_NAME}.pth'\n",
    "        export_model_to_csv(model, test_loader, save_images=SAVE_IMAGES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.load_state_dict(torch.load(CHECKPOINT_PATH))\n",
    "    model.eval()\n",
    "    metrics = SegMetric(n_classes = 19)\n",
    "    metrics.reset()\n",
    "    total_loss = 0\n",
    "    seq = 0\n",
    "    with torch.no_grad():\n",
    "        if UNSEEN:\n",
    "            for images, _, idx, aligned_size, original_img_shape, r_mat in tqdm(test_loader):\n",
    "                \n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                images, predicted, _ = inverseTensor(images, predicted, images, aligned_size, original_img_shape, r_mat, unseen=True)\n",
    "                print(predicted.shape)\n",
    "                \n",
    "                if JUPYTER_NOTEBOOK:\n",
    "                    if True:\n",
    "                        visualize_predictions_jupyter(images, predicted, None, unseen=True)\n",
    "        else:\n",
    "            for images, masks, idx, aligned_size, original_img_shape, r_mat in tqdm(test_loader):\n",
    "                \n",
    "                images, masks = images.to(device), masks.to(device).squeeze(1)\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, masks)\n",
    "                \n",
    "                total_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                \n",
    "                # Update F1 score\n",
    "                pred = outputs.data.max(1)[1].cpu().numpy()  # Matrix index\n",
    "                gt = combine_masks(masks).cpu().numpy()\n",
    "                metrics.update(gt, pred)\n",
    "                seq += 1\n",
    "                \n",
    "                images, predicted, masks = inverseTensor(images, predicted, masks, aligned_size, original_img_shape, r_mat)\n",
    "                \n",
    "                if JUPYTER_NOTEBOOK:\n",
    "                    # if seq % 100 == 0 and seq < 400:\n",
    "                    if True:\n",
    "                        visualize_predictions_jupyter(images, predicted, masks)\n",
    "                else:\n",
    "                    output_dir = os.path.join(log_dir, 'images')\n",
    "                    if not os.path.exists(output_dir):\n",
    "                        os.makedirs(output_dir)\n",
    "                    visualize_predictions(images, predicted, masks, idx, base_path=output_dir)\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    F1_score = metrics.get_f1_score()\n",
    "    print(f'Test Loss: {avg_loss:.4f}, F1 Score: {F1_score:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "670676dab13b4b1396e1217a2ff9beb1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2169218eba97451a97eb2868f87fe285",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Training loop\n",
    "if MODE == 'train':\n",
    "    train(model, train_loader, test_loader, criterion, optimizer)\n",
    "elif MODE == 'test':\n",
    "    test(model, test_loader)\n",
    "elif MODE == 'csv':\n",
    "    export_model_to_csv(model, test_loader, save_images=SAVE_IMAGES)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cvwork",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
